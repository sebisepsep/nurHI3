Each dataset contains the number and position of satellite galaxies and the number of halos.\\
Step 1:\\
\begin{itemize}
    \item number of radial bins: 75
    \item space: real
    \item range: per iteration max(r)
\end{itemize}
I have chosen 75 bins for every plot because I observed the number of galaxies for each dataset and wanted even the smallest one to have a representative number of bins. The maximum value changes for each dataset to avoid many empty bins. Additionally, since there was an opportunity to use real spacing, I utilized it because I personally find it more intuitive. On the other hand, I haven't seen the advantage of logarithmic spacing.
Step 2: \\
Calculate the mean number of galaxies per halo per dataset:
\begin{align}
    \langle N_{sat} \rangle = \frac{\# Galaxies}{\# Halos}
\end{align}
Bin the satellite galaxy radii to get a mean number of satellites:
\begin{align}
    N[i] &= \# Galaxies \in [x_i,x_{i+1}]\\
    N &= \frac{N}{\# Halos}
\end{align}
These are our datapoints. \\
Now we want to minimize a $\chi^2$:
\begin{align}
    \chi^2 &= \sum_i \frac{\q{N_i-\text{Model}_i(a,b,c)}^2}{\sigma_i^2}\\
    \chi^2 &= \sum_i \frac{\q{N_i-\Tilde{N}_i(a,b,c)}^2}{\Tilde{N}_i(a,b,c)_i^2}
\end{align}
Where:
\begin{align}
    \Tilde{N}_i(a,b,c) &= 4 \pi \int_{x_i}^{x_{i+1}}n(x,a,b,c)x^2dx \\
    &= 4 \pi A(a,b,c)\cdot \langle N_{sat} \rangle \f{1}{b}^{a-3}  \int_{x_i}^{x_{i+1}}x^{a-1} \exp\q{-\f{x}{b}^{c}} dx
\end{align}
With:
\begin{align}
    n(a,b,c,x) &= A(a,b,c)\cdot \langle N_{sat} \rangle \f{x}{b}^{a-3} \exp\q{-\f{x}{b}^{c}}\\
    A(a,b,c) &= \q{4\pi \f{1}{b}^{a-3} \int_0^{x_{max}} x^{a-1} \exp\q{-\f{x}{b}^c} dx}^{-1}
\end{align}


In the figures, we can see the best-fit data of the chi-squared fit and the binned data. In this task, we used a combination of the conjugate gradient method and the golden ratio search. It is obvious that neither of the fits fits the data well. Also, from the golden ratio search, we saw that we are not really changing the initial parameters in this configuration. In the worst case, we ended up with an unchanging value in the golden ratio search. To prevent this, we added a part that tightens the bracket so that we might get closer to the minimum of the linear minimization. Unfortunately, the values didn't change, so this fit is a valid approximation of the data. Every time when the title of a figure says "error in golden ratio," it means that this method was stuck, and therefore, the result return value was the same as before, and our check value was zero. The best-fit data is therefore completely dominated by the initial values. I also tried many initial parameters, and it was also possible that the plots would align more, but still, this was only related to the initial setting. On the other hand, I tried this algorithm with many functions depending on three values and minimized it, and so far, this always worked. So there might also be another mistake in the chi-squared formula. I'm aware that the plots should be log-log, but since I have chosen a real spacing, it will only mess up the whole diagram. Also, the whole algorithm was quite sensitive to changes in accuracies and initial brackets for the line minimization.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{dataset_1_plotb.jpg}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{dataset_2_plotb.jpg}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{dataset_3_plotb.jpg}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{dataset_4_plotb.jpg}
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{dataset_5_plotb.jpg}
\end{figure}

\lstinputlisting{dataset_0_paramsb.txt}
\lstinputlisting{dataset_1_paramsb.txt}
\lstinputlisting{dataset_2_paramsb.txt}
\lstinputlisting{dataset_3_paramsb.txt}
\lstinputlisting{dataset_4_paramsb.txt}
\lstinputlisting{b_ref.py}
